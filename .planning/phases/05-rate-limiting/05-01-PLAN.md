---
phase: 05-rate-limiting
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/errors.ts
  - src/server/discogs/retry.ts
  - src/server/discogs/rate-state.ts
autonomous: true

must_haves:
  truths:
    - '429 errors from discojs are caught and retried with exponential backoff'
    - 'RateLimitError is thrown after retries exhausted with remaining wait time'
    - 'Rate limit state is trackable from API responses'
  artifacts:
    - path: 'src/lib/errors.ts'
      provides: 'RateLimitError class definition (shared module)'
      exports: ['RateLimitError']
    - path: 'src/server/discogs/retry.ts'
      provides: 'Retry wrapper with exponential backoff and jitter'
      exports: ['withRateLimitRetry', 'isRateLimitError', 'calculateBackoff']
    - path: 'src/server/discogs/rate-state.ts'
      provides: 'Rate limit state tracking infrastructure (estimated values)'
      exports:
        [
          'RateLimitState',
          'rateLimitState',
          'updateRateLimitState',
          'getRateLimitState'
        ]
  key_links:
    - from: 'src/server/discogs/retry.ts'
      to: 'src/lib/errors.ts'
      via: 'import RateLimitError'
      pattern: "import.*RateLimitError.*from '@/lib/errors'"
    - from: 'src/server/discogs/retry.ts'
      to: 'discojs.DiscogsError'
      via: 'import and instanceof check'
      pattern: 'instanceof DiscogsError'
---

<objective>
Create rate limiting infrastructure for 429 error handling and rate state exposure.

Purpose: Enable reactive recovery from Discogs API rate limits and provide observability for downstream consumers (tRPC handlers, UI). discojs already handles proactive throttling via built-in Bottleneck — this plan adds the missing reactive layer.

Output: Retry wrapper module, rate state tracking module, RateLimitError type exported for client use.
</objective>

<execution_context>
@/Users/danieldjupvik/.claude/get-shit-done/workflows/execute-plan.md
@/Users/danieldjupvik/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-rate-limiting/05-CONTEXT.md
@.planning/phases/05-rate-limiting/05-RESEARCH.md

# Existing codebase reference

@src/lib/errors.ts
@src/lib/constants.ts
@src/api/rate-limiter.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define RateLimitError in shared lib/errors.ts</name>
  <files>src/lib/errors.ts</files>
  <action>
Add RateLimitError class to `src/lib/errors.ts` (shared module, importable by both client and server):

1. **RateLimitError class** (add after OfflineNoCacheError):

   ````typescript
   /**
    * Error thrown when Discogs API rate limit is exceeded and retries are exhausted.
    * Contains timing info for upstream layers to display user feedback.
    *
    * @example
    * ```ts
    * catch (error) {
    *   if (error instanceof RateLimitError) {
    *     showToast(`Try again in ${Math.ceil(error.retryAfterMs / 1000)}s`)
    *   }
    * }
    * ```
    */
   export class RateLimitError extends Error {
     readonly retryAfterMs: number
     readonly statusCode = 429

     constructor(retryAfterMs: number) {
       super(
         `Rate limit exceeded. Retry after ${Math.ceil(retryAfterMs / 1000)}s`
       )
       this.name = 'RateLimitError'
       this.retryAfterMs = retryAfterMs
     }
   }
   ````

2. **Update isNonRetryableError function:**
   - Add check: `if (error instanceof RateLimitError) return true`
   - Keep existing tRPC error code checks

This keeps RateLimitError in the shared lib module (correct import direction: server imports from lib, not vice versa).
</action>
<verify>
`bun run build` succeeds
`grep "class RateLimitError" src/lib/errors.ts` shows class definition
</verify>
<done>

- RateLimitError class defined in shared lib/errors.ts
- Follows existing pattern from OfflineNoCacheError
- isNonRetryableError updated to recognize RateLimitError
- Both client and server can import from '@/lib/errors'
  </done>
  </task>

<task type="auto">
  <name>Task 2: Create retry wrapper infrastructure</name>
  <files>src/server/discogs/retry.ts</files>
  <action>
Create `src/server/discogs/retry.ts` with:

1. **Imports:**
   - `import { DiscogsError } from 'discojs'`
   - `import { RateLimitError } from '@/lib/errors'` (or relative: `'../../../lib/errors.js'` for serverless)

2. **isRateLimitError type guard:**
   - Returns `error instanceof DiscogsError && error.statusCode === 429`
   - Type predicate: `error is DiscogsError`

3. **calculateBackoff function:**
   - Parameters: `attempt: number`, `baseDelayMs = 1000`
   - Formula: `baseDelayMs * Math.pow(2, attempt)` for exponential
   - Add jitter: `Math.random() * exponential * 0.3` (0-30%)
   - Cap at 60000ms (1 minute max)
   - Return `Math.min(exponential + jitter, 60000)`

4. **delay helper:**
   - `const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms))`

5. **withRateLimitRetry generic wrapper:**
   - Signature: `async function withRateLimitRetry<T>(fn: () => Promise<T>, options?: { maxRetries?: number, baseDelayMs?: number }): Promise<T>`
   - Default maxRetries: 3
   - Default baseDelayMs: 1000
   - Loop: for attempt 0 to maxRetries
     - Try: return await fn()
     - Catch: if !isRateLimitError(error), rethrow immediately
     - If attempt === maxRetries: throw new RateLimitError(calculateBackoff(attempt, baseDelayMs))
     - Otherwise: await delay(calculateBackoff(attempt, baseDelayMs))
   - Add TSDoc explaining when to use (wrap discojs calls)

Use .js extension for relative imports (Vercel serverless compatibility).
Re-export RateLimitError for convenience: `export { RateLimitError } from '@/lib/errors'`
</action>
<verify>
`bun run build` succeeds with no TypeScript errors in retry.ts
`grep "import.*RateLimitError" src/server/discogs/retry.ts` shows correct import direction
</verify>
<done>

- retry.ts imports RateLimitError from lib/errors (correct direction)
- isRateLimitError correctly identifies DiscogsError with statusCode 429
- withRateLimitRetry wrapper implements exponential backoff with jitter
- All exports are properly typed
  </done>
  </task>

<task type="auto">
  <name>Task 3: Create rate state tracking infrastructure</name>
  <files>src/server/discogs/rate-state.ts</files>
  <action>
Create `src/server/discogs/rate-state.ts` with:

1. **RateLimitState interface:**

   ```typescript
   export interface RateLimitState {
     /** Total requests allowed per minute (60 auth, 25 unauth) */
     limit: number
     /** Requests remaining in current window */
     remaining: number
     /** Estimated Unix timestamp (ms) when window resets (approximation - may drift from server) */
     resetAt: number
     /** Last update timestamp (ms) */
     updatedAt: number
   }
   ```

2. **Default state constant:**
   - Import RATE_LIMIT from '@/lib/constants' (use relative path for serverless: '../../../lib/constants.js')
   - Default: `{ limit: RATE_LIMIT.MAX_REQUESTS, remaining: RATE_LIMIT.MAX_REQUESTS, resetAt: 0, updatedAt: 0 }`

3. **rateLimitState singleton:**
   - Module-level mutable object initialized to default
   - Use `let` for reassignment capability
   - Note: Single-user per deployment (VinylDeck architecture), so singleton is appropriate

4. **getRateLimitState function:**
   - Returns readonly copy: `{ ...rateLimitState } as Readonly<RateLimitState>`
   - Prevents external mutation

5. **updateRateLimitState function:**
   - Signature: `(update: Partial<Pick<RateLimitState, 'limit' | 'remaining'>>) => void`
   - Only accepts limit and remaining (other fields computed)
   - If limit provided and valid: update rateLimitState.limit
   - If remaining provided and valid: update rateLimitState.remaining
   - Always set updatedAt to Date.now()
   - Calculate resetAt: updatedAt + RATE_LIMIT.WINDOW_MS

6. **resetRateLimitState function:**
   - Resets to default state
   - Used when window expires or auth changes

Add TSDoc to all exports. Note that resetAt is an estimate (Codex review feedback).
</action>
<verify>
`bun run build` succeeds
`grep -r "RateLimitState" src/server/discogs/` shows interface and usage
</verify>
<done>

- RateLimitState interface with TSDoc noting resetAt is estimated
- Singleton appropriate for single-user-per-deployment architecture
- updateRateLimitState accepts partial updates
- getRateLimitState returns immutable copy
  </done>
  </task>

</tasks>

<verification>
After all tasks complete:

1. **Build verification:**

   ```bash
   bun run build
   ```

   Must complete with no TypeScript errors.

2. **Import direction verification (Codex review fix):**

   ```bash
   grep "import.*RateLimitError" src/server/discogs/retry.ts
   ```

   Must show import FROM lib/errors (not the other way around).

3. **Export verification:**

   ```bash
   grep -r "export" src/server/discogs/retry.ts src/server/discogs/rate-state.ts src/lib/errors.ts | grep -E "(RateLimitError|withRateLimitRetry|RateLimitState)"
   ```

   Must show all expected exports.

4. **Vercel build (critical):**
   ```bash
   vercel build
   ```
   Must succeed — serverless functions have stricter module resolution.
   </verification>

<success_criteria>

1. **RATE-01 (partial):** Rate limiting module exists at src/server/discogs/ (full throttle.ts deferred - discojs handles proactive throttling)
2. **RATE-02, RATE-03:** Constants already exist in src/lib/constants.ts (60 req/min, 25 req/min) - rate-state.ts uses them
3. **RATE-04:** 429 errors handled via withRateLimitRetry with exponential backoff + jitter, RateLimitError thrown after exhausted retries
4. **RATE-05:** Rate state exposed via getRateLimitState() for UI consumption
5. **RATE-06 (partial):** Wrapper ready for use - actual wrapping happens in Phase 6 (Facade) and Phase 7 (tRPC Integration)

Infrastructure complete, ready for Phase 6 to wire into facade layer.
</success_criteria>

<output>
After completion, create `.planning/phases/05-rate-limiting/05-01-SUMMARY.md`
</output>
